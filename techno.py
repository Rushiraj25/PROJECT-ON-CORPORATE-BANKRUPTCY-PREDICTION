# -*- coding: utf-8 -*-
"""Techno.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v6KpvW_k4td2i5bdUVUO3n1djTC9uvjE

# CORPORATE-BANKRUPTCY-PREDICTION

# #Data Preprocessing
"""

from scipy.io import arff
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
data =arff.loadarff('/content/drive/MyDrive/data/1year.arff')
data1 =arff.loadarff('/content/drive/MyDrive/data/2year.arff')
data2 = arff.loadarff('/content/drive/MyDrive/data/3year.arff')
data3=arff.loadarff('/content/drive/MyDrive/data/4year.arff')
data4=arff.loadarff('/content/drive/MyDrive/data/5year.arff')
bank1 = pd.DataFrame(data[0])
bank2 = pd.DataFrame(data1[0])
bank3 = pd.DataFrame(data2[0])
bank4 = pd.DataFrame(data3[0])
bank5 = pd.DataFrame(data4[0])

bank = pd.concat([bank1,bank2,bank3,bank4,bank5])

bank.head(10)

bank.isna().sum()

bank.astype(float)
bank.dtypes

bank['class'] = bank['class'].astype('int64')
bank.dtypes

plt.figure(figsize=(10,10))
sns.heatmap(bank.isnull(), cbar=False)

for feature in bank.columns:
    m=bank[feature].mean()
    bank[feature].fillna(m,inplace=True)
print(bank.isna().any().sum())

# visualize the target variable
sns.countplot(bank['class'])
plt.show()

bank['class'].value_counts()

#! pip install yellowbrick==0.9.1 scikit-learn==0.22.2

from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

bank['class'].value_counts()

from sklearn.model_selection import train_test_split
 
# split into 70:30 ration
X = np.array(bank.iloc[:,0:64]) # Predictors 
y = np.array(bank['class']) # Target 

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)
 
# describes info about train and test set
#print("Number transactions X_train dataset: ", X_train.shape)
#print("Number transactions y_train dataset: ", y_train.shape)
#print("Number transactions X_test dataset: ", X_test.shape)

sm = SMOTE()
X_res, y_res = sm.fit_resample(X,y)

X_res.shape

y_res.shape

sns.countplot(y_res)

X_res

y_res

x= pd.DataFrame(X_res)
y= pd.DataFrame(y_res)

bankcorp= x.append(y)

bankcorp



"""# reproducibility purposes
seed = 10000
# SMOTE number of neighbors
k = 5
sm = SMOTE(sampling_strategy='auto', k_neighbors=k, random_state=seed)
X_res, y_res = sm.fit_resample(X, y)

plt.title('Dataset balanced with SMOTE data ({} neighbors)'.format(k))
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(X_res[:, 0], X_res[:, 1], marker='o', c=y_res,
           s=25, edgecolor='k', cmap=plt.cm.coolwarm)
plt.show()

print("Before Undersampling, counts of label '1': {}".format(sum(y_train == 1)))
print("Before Undersampling, counts of label '0': {} \n".format(sum(y_train == 0)))
 
print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))
print('After OverSampling, the shape of train_y: {} \n'.format(y_train_res.shape))
 
print("After OverSampling, counts of label '1': {}".format(sum(y_train_res == 1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_train_res == 0)))
"""